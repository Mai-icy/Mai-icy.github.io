<!DOCTYPE html>
<html>
  <head>
     
    <meta charset="UTF-8">
    <title>本地部署大模型Qwen-math-7b - Mai Icy</title>
    <link rel="shortcut icon" href="/static/img/icon.png">
    <link rel="icon" href="/static/img/icon.png" sizes="192x192"/>
    
<link rel="stylesheet" href="/static/kico.css">
<link rel="stylesheet" href="/static/hingle.css">

    
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <meta name="viewport" content="width=device-width, maximum-scale=1, initial-scale=1"/>
    <meta property="og:site_name" content="Mai Icy">
    <meta property="og:title" content="本地部署大模型Qwen-math-7b"/>
    
<meta name="generator" content="Hexo 6.2.0"></head>

  <body>
    <header>
    <div class="head-title">
        <h4>Mai Icy</h4>
    </div>
    <div class="head-action">
        <div class="toggle-btn"></div>
        <div class="light-btn"></div>
        <div class="search-btn"></div>
    </div>
    <form class="head-search" method="post">
        <input type="text" name="s" placeholder="搜索什么？">
    </form>
    <nav class="head-menu">
        <a href="/">首页</a>
        <div class="has-child">
            <a>分类</a>
            <div class="sub-menu">
                <a class="category-link" href="/categories/C/">C</a><a class="category-link" href="/categories/python/">python</a><a class="category-link" href="/categories/rust/">rust</a><a class="category-link" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a><a class="category-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a><a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="category-link" href="/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">算法学习笔记</a><a class="category-link" href="/categories/%E7%AE%97%E6%B3%95%E8%AF%BE%E7%AC%94%E8%AE%B0/">算法课笔记</a><a class="category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/">计算机网络笔记</a>
            </div>
        </div>
        
            <a href="/about">关于我</a>
        
            <a href="/friends">朋友们</a>
        
    </nav>
</header>

    <main>
    <div class="wrap min">
        <section class="post-title">
            <h2>本地部署大模型Qwen-math-7b</h2>
            <div class="post-meta">
                <time class="date">2025.02.25</time>
            
                <span class="category"><a class="category-link" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a></span>
            
            </div>
        </section>
        <article class="post-content">
        
            <p>本次部署为简单概述流程，本地配置为4060Ti-16G，采用7b模型部署。</p>
<h1>下载模型</h1>
<p>注：模型实际上可以直接在线使用，此处只为便于离线使用。</p>
<p>模型通常开源于 huggingface，一个大模型开源网站，开源了大量模型，本次模型地址：<a target="_blank" rel="noopener" href="https://huggingface.co/Qwen/Qwen2.5-Math-7B">Qwen-math-7b</a>。模型地址通常类似于github即是一个在线的git仓库，也就是能使用git进行克隆。</p>
<h2 id="git-lfs">git lfs</h2>
<p>对于大模型而言，拥有较大的模型文件，git对于版本的管理需要存储文件的存储拷贝，对于多个历史版本，较大的文件在本地有多份拷贝会使git管理繁琐，并会使文件体积大幅度膨胀。git lfs作为git的拓展提供了一个解决方法，其将大文件的历史存储在远程服务器上，git仓库仅存储大文件的指针，在需要对应历史的大文件的时候，就会自动从远程服务器中获取。</p>
<p>对于本次的模型克隆，即</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> lfs clone https://huggingface.co/Qwen/Qwen2.5-Math-7B<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>等待下载完即可</p>
<h2 id="huggingface-hub">huggingface_hub</h2>
<p>这是 Hugging Face 提供的一个 Python 库，用于与 Hugging Face Hub 进行交互。Hugging Face Hub 是一个用于存储和共享模型、数据集、预训练权重等资源的平台，广泛应用于自然语言处理（NLP）和其他深度学习任务。重要的是，它可以轻松地下载 Hugging Face 上的模型、数据集和文件。例如，你可以从 Hub 下载预训练的 Transformer 模型，或者自定义的模型和数据集。</p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/docs/huggingface_hub/v0.17.3/en/package_reference/file_download">官方文档</a></p>
<h3 id="hf-hub-download"><strong>hf_hub_download</strong></h3>
<p>这是其提供的一个函数，用于下载单个文件</p>
<p>主要有以下的参数（*必须参数）：</p>
<ul>
<li>repo_id(*)：仓库名</li>
<li>filename(*)：需要下载的单个文件名</li>
<li>local_dir：下载保存的目录</li>
<li>endpoint：可以填入镜像站，默认是<a target="_blank" rel="noopener" href="https://huggingface.co/%EF%BC%8C%E4%BE%8B%E5%A6%82%E6%88%91%E4%BB%AC%E4%BD%BF%E7%94%A8%E5%85%B6%E5%AE%83%E9%95%9C%E5%83%8F%EF%BC%8C%E5%8F%AA%E9%9C%80%E8%A6%81%E6%94%BE%E5%85%A5%E9%95%9C%E5%83%8F%E7%9A%84%E7%BD%91%E7%AB%99%E5%8D%B3%E5%8F%AF">https://huggingface.co/，例如我们使用其它镜像，只需要放入镜像的网站即可</a></li>
</ul>
<h3 id="snapshot-download"><strong>snapshot_download</strong></h3>
<p>用于下载整个仓库的快照</p>
<p>主要有以下的参数（*必须参数）：</p>
<ul>
<li>repo_id(*)：仓库名</li>
<li>local_dir：下载保存的目录</li>
<li>endpoint：可以填入镜像站。</li>
</ul>
<h3 id="huggingface-cli">huggingface-cli</h3>
<p>可以使用快速下载的脚手架，例如以下：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">huggingface-cli download gpt2 config.json<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="镜像站">镜像站</h3>
<p>对于国内的网络环境，为节省流量以及提高下载效率，故使用huggingface的镜像站对于国内用户更加合适：</p>
<p><a target="_blank" rel="noopener" href="https://hf-mirror.com/">镜像站 hf-mirror</a>，<a target="_blank" rel="noopener" href="https://www.modelscope.cn/">镜像站 modelscope</a></p>
<p>镜像站进行前面的替换即可</p>
<h1>部署模型</h1>
<p>部署模型采用Transformers调用，Hugging Face 开发的 Transformers 库是一个由 Hugging Face 提供的开源库，旨在简化和统一深度学习模型，特别是基于 Transformer 架构的模型（如 BERT、GPT、T5 等）的使用。它为各种自然语言处理（NLP）任务提供了预训练模型和方便的 API，使得开发者能够轻松地进行模型的训练、微调和推理。</p>
<h2 id="载入模型">载入模型</h2>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> AutoTokenizer

<span class="token keyword">def</span> <span class="token function">load_model</span><span class="token punctuation">(</span>model_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> <span class="token string">"cuda:0"</span>

    model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
        model_path<span class="token punctuation">,</span>
        torch_dtype<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">,</span>
        device_map<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">""</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
        use_safetensors<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

    <span class="token keyword">return</span> device<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> model<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Tokenizer">Tokenizer</h3>
<p>分词器（Tokenizer）是自然语言处理（NLP）中的一个重要组件，它的主要作用是将原始文本（例如句子或段落）转换为模型可以理解的形式。对于深度学习模型，尤其是基于 Transformer 架构的模型（如 BERT、GPT 等），分词器将文本切分为更小的单元（通常是单词或子词），并将这些单元转换为对应的数字 ID，作为模型的输入。</p>
<p>分词器通常和模型是配对的，因此下载来的模型文件夹包含了模型文件和分词器配置，可以载入</p>
<h3 id="载入模型参数介绍">载入模型参数介绍</h3>
<p>注：AutoTokenizer的载入并不需要大量显存也不属于模型，故载入的时候不需要后两个参数。</p>
<p>仅介绍一部分参数</p>
<ul>
<li>model_name_or_path：指定预训练模型的名称或路径。可以是 Hugging Face Model Hub 上的模型标识符，也可以是本地文件系统上的路径。</li>
<li>cache_dir：缓存目录</li>
<li>force_download：即使在缓存中已有模型的情况下，也强制重新下载模型</li>
<li>resume_download：如果下载被中断，则从中断的地方继续下载。</li>
<li>proxies：代理</li>
<li>torch_dtype：设置加载模型时使用的 PyTorch dtype。这对于模型精度和性能调优特别有用</li>
<li>device_map：控制模型的计算图如何分配到不同的设备（如GPU、CPU）上，
<ul>
<li>&quot;sequential”模型按顺序加载到多个GPU上</li>
<li>&quot;auto”会自动优化分配</li>
<li>device_map={“”: “cuda:0”}：手动分配到GPU0</li>
</ul>
</li>
</ul>
<h2 id="使用模型输入输出（Quick-Start）">使用模型输入输出（Quick Start）</h2>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">chat_qwen</span><span class="token punctuation">(</span>device<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> model<span class="token punctuation">,</span> messages<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># 使用分词器的 apply_chat_template 方法将消息格式化为模型可理解的输入格式</span>
    text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>apply_chat_template<span class="token punctuation">(</span>messages<span class="token punctuation">,</span> tokenize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> add_generation_prompt<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    model_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    <span class="token comment"># 生成模型输出</span>
    generated_ids <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
        model_inputs<span class="token punctuation">.</span>input_ids<span class="token punctuation">,</span>
        max_new_tokens<span class="token operator">=</span><span class="token number">512</span>
    <span class="token punctuation">)</span>

    <span class="token comment"># 由于模型输出包括输入模型，这里切去输入部分</span>
    generated_ids <span class="token operator">=</span> <span class="token punctuation">(</span>output_ids<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token keyword">for</span> input_ids<span class="token punctuation">,</span> output_ids <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>model_inputs<span class="token punctuation">.</span>input_ids<span class="token punctuation">,</span> generated_ids<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 将模型输出解码为文本</span>
    response <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>generated_ids<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    <span class="token keyword">return</span> response<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>对于模型的使用而言，需要知道最基础的一部分知识。</p>
<p>对于模型，其接受的文本首先要经过分词器处理，才能得出结果，并且其结果也要经过分词器解码，类似于和外星人聊天之间的翻译官，对于本模型而言，即给他一段对话环境作为输入，他将输出一句新的话作为补充回复。</p>
<h3 id="设置输入消息">设置输入消息</h3>
<p>大模型中通常有三个角色：system，user，assistant。在openai给出的GPT文档中，还有developer类的角色。</p>
<ul>
<li>system类消息：开发人员提供的模型应该遵循的指令，而不管用户发送的消息是什么。</li>
<li>user类消息：由最终用户发送的消息，包含提示或其他上下文信息。</li>
<li>assistent类消息：模型为响应用户消息而发送的消息。</li>
</ul>
<p>由这些消息组成以作为输入提供给大模型。</p>
<h3 id="消息格式化编码化">消息格式化编码化</h3>
<p>apply_chat_template 函数就用于格式化上面设置的消息</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">'role'</span><span class="token builtin class-name">:</span> <span class="token string">'system'</span>, <span class="token string">'content'</span><span class="token builtin class-name">:</span> <span class="token string">'You are a helpful assistant.'</span><span class="token punctuation">&#125;</span>, <span class="token punctuation">&#123;</span><span class="token string">'role'</span><span class="token builtin class-name">:</span> <span class="token string">'user'</span>, 
<span class="token string">'content'</span><span class="token builtin class-name">:</span> <span class="token string">'你是谁？'</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>通过格式化化变为</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token operator">&lt;</span><span class="token operator">|</span>im_start<span class="token operator">|</span><span class="token operator">></span>system
 You are a helpful assistant.<span class="token operator">&lt;</span><span class="token operator">|</span>im_end<span class="token operator">|</span><span class="token operator">></span>
 <span class="token operator">&lt;</span><span class="token operator">|</span>im_start<span class="token operator">|</span><span class="token operator">></span>user
你是谁？<span class="token operator">&lt;</span><span class="token operator">|</span>im_end<span class="token operator">|</span><span class="token operator">></span>
 <span class="token operator">&lt;</span><span class="token operator">|</span>im_start<span class="token operator">|</span><span class="token operator">></span>assistant<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>再通过tokenizer来对消息进行编码</p>
<p>将处理后的文本通过分词器转换为模型需要的输入格式，return_tensors=“pt” 表示返回 PyTorch 张量格式，并将输入传送到前面指定的设备上</p>
<h3 id="获取输出并解码">获取输出并解码</h3>
<p>模型的输出实际包含输入的数据，因此将输入的数据切片后解码即可。</p>
<h3 id="使用例">使用例</h3>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token char">'__main__'</span><span class="token operator">:</span>
    MODEL <span class="token operator">=</span> <span class="token string">"Qwen2.5-Math-7B"</span>
    pak <span class="token operator">=</span> <span class="token function">load_model</span><span class="token punctuation">(</span>MODEL<span class="token punctuation">)</span>
    msgs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">"role"</span><span class="token operator">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span>
             <span class="token string">"content"</span><span class="token operator">:</span> <span class="token string">"你是一个数学方面的助手，需要帮助用户解决数学问题，要求答案正确，并且要提供思考步骤。"</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span>
    <span class="token keyword">while</span> True<span class="token operator">:</span>
        ques <span class="token operator">=</span> <span class="token function">input</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        msgs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"role"</span><span class="token operator">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token operator">:</span> ques<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>

        <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"接受到问题开始思考"</span><span class="token punctuation">)</span>
        res <span class="token operator">=</span> <span class="token function">chat_qwen</span><span class="token punctuation">(</span><span class="token operator">*</span>pak<span class="token punctuation">,</span> msgs<span class="token punctuation">)</span>
        <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"思考完毕"</span><span class="token punctuation">)</span>
        <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"回答："</span><span class="token punctuation">,</span> res<span class="token punctuation">)</span>
        msgs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"role"</span><span class="token operator">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token operator">:</span> res<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>

        <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"当前问答链"</span><span class="token punctuation">)</span>
        <span class="token function">pprint</span><span class="token punctuation">(</span>msgs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个例子可以多次和模型进行问答，并且还可以记录历史的问答，让模型具有记忆。</p>
<h1>结合到Longchain</h1>
<p><a target="_blank" rel="noopener" href="https://python.langchain.com/docs/how_to/custom_llm/">文档</a></p>
<p>按照文档，把定制模型置入即可，以下供参考</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">QwenMath</span><span class="token punctuation">(</span>LLM<span class="token punctuation">)</span><span class="token operator">:</span>
    # 模型参数
    max_new_tokens<span class="token operator">:</span> <span class="token keyword">int</span> <span class="token operator">=</span> <span class="token number">1920</span>
    temperature<span class="token operator">:</span> <span class="token keyword">float</span> <span class="token operator">=</span> <span class="token number">0.9</span>
    top_p<span class="token operator">:</span> <span class="token keyword">float</span> <span class="token operator">=</span> <span class="token number">0.8</span>
    tokenizer<span class="token operator">:</span> object <span class="token operator">=</span> None
    model<span class="token operator">:</span> object <span class="token operator">=</span> None
    history<span class="token operator">:</span> List <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    device<span class="token operator">:</span> object <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">device</span><span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span><span class="token function">is_available</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> max_new_tokens<span class="token operator">=</span><span class="token number">1920</span><span class="token punctuation">,</span>
                 temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>
                 top_p<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token function">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>max_new_tokens <span class="token operator">=</span> max_new_tokens
        self<span class="token punctuation">.</span>temperature <span class="token operator">=</span> temperature
        self<span class="token punctuation">.</span>top_p <span class="token operator">=</span> top_p

    @property
    def <span class="token function">_llm_type</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-></span> str<span class="token operator">:</span>
        <span class="token keyword">return</span> <span class="token string">"Qwen2"</span>

    def <span class="token function">load_model</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_name_or_path<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token operator">:</span>
        self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span><span class="token function">from_pretrained</span><span class="token punctuation">(</span>
            model_name_or_path<span class="token punctuation">,</span>
            trust_remote_code<span class="token operator">=</span>True
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span><span class="token function">from_pretrained</span><span class="token punctuation">(</span>
            model_name_or_path<span class="token punctuation">,</span>
            torch_dtype<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">,</span>
            <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">torch</span><span class="token expression">_dtype<span class="token operator">=</span></span><span class="token string">"torch.float16"</span><span class="token expression"><span class="token punctuation">,</span></span></span>
            device_map<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">""</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>  # sequential<span class="token operator">/</span><span class="token keyword">auto</span><span class="token operator">/</span>balanced_low_0
        <span class="token punctuation">)</span>

    def <span class="token function">chat_stream</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> query<span class="token operator">:</span> str<span class="token punctuation">,</span> history<span class="token operator">:</span> list<span class="token punctuation">)</span><span class="token operator">:</span>
        with torch<span class="token punctuation">.</span><span class="token function">no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
            # 历史整理
            messages <span class="token operator">=</span> <span class="token punctuation">[</span>
                <span class="token punctuation">&#123;</span><span class="token char">'role'</span><span class="token operator">:</span> <span class="token char">'system'</span><span class="token punctuation">,</span> <span class="token char">'content'</span><span class="token operator">:</span> '你是一个数学方面的助手，需要帮助用户解决数学问题，要求答案正确，并且要提供思考步骤。'<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
            <span class="token punctuation">]</span>
            # 将之前的history内容重新组合
            <span class="token keyword">for</span> item in history<span class="token operator">:</span>
                <span class="token keyword">if</span> item<span class="token punctuation">[</span><span class="token char">'role'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token char">'user'</span><span class="token operator">:</span>
                    <span class="token keyword">if</span> item<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token char">'content'</span><span class="token punctuation">)</span><span class="token operator">:</span>
                        messages<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token char">'role'</span><span class="token operator">:</span> <span class="token char">'user'</span><span class="token punctuation">,</span> <span class="token char">'content'</span><span class="token operator">:</span> item<span class="token punctuation">[</span><span class="token char">'content'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> item<span class="token punctuation">[</span><span class="token char">'role'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token char">'assistant'</span><span class="token operator">:</span>
                    <span class="token keyword">if</span> item<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token char">'content'</span><span class="token punctuation">)</span><span class="token operator">:</span>
                        messages<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token char">'role'</span><span class="token operator">:</span> <span class="token char">'assistant'</span><span class="token punctuation">,</span> <span class="token char">'content'</span><span class="token operator">:</span> item<span class="token punctuation">[</span><span class="token char">'content'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
            # 最新的用户问题
            messages<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token char">'role'</span><span class="token operator">:</span> <span class="token char">'user'</span><span class="token punctuation">,</span> <span class="token char">'content'</span><span class="token operator">:</span> query<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
            # 模型推理
            text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span><span class="token function">apply_chat_template</span><span class="token punctuation">(</span>
                messages<span class="token punctuation">,</span>
                tokenize<span class="token operator">=</span>False<span class="token punctuation">,</span>
                add_generation_prompt<span class="token operator">=</span>True
            <span class="token punctuation">)</span>

            model_inputs <span class="token operator">=</span> <span class="token function">tokenizer</span><span class="token punctuation">(</span><span class="token punctuation">[</span>text<span class="token punctuation">]</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">to</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

            generated_ids <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token function">generate</span><span class="token punctuation">(</span>
                <span class="token operator">*</span><span class="token operator">*</span>model_inputs<span class="token punctuation">,</span>
                max_new_tokens<span class="token operator">=</span>self<span class="token punctuation">.</span>max_new_tokens<span class="token punctuation">,</span>
                do_sample<span class="token operator">=</span>False<span class="token punctuation">,</span>
                top_p<span class="token operator">=</span>self<span class="token punctuation">.</span>top_p<span class="token punctuation">,</span>
                temperature<span class="token operator">=</span>self<span class="token punctuation">.</span>temperature
            <span class="token punctuation">)</span>
            generated_ids <span class="token operator">=</span> <span class="token punctuation">[</span>
                output_ids<span class="token punctuation">[</span><span class="token function">len</span><span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span><span class="token operator">:</span><span class="token punctuation">]</span> <span class="token keyword">for</span> input_ids<span class="token punctuation">,</span> output_ids in <span class="token function">zip</span><span class="token punctuation">(</span>model_inputs<span class="token punctuation">.</span>input_ids<span class="token punctuation">,</span> generated_ids<span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
            # 模型根据messages的内容后的输出
            response <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span><span class="token function">batch_decode</span><span class="token punctuation">(</span>generated_ids<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span>True<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            # 将模型输出组合到messages中
            messages<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token char">'role'</span><span class="token operator">:</span> <span class="token char">'assistant'</span><span class="token punctuation">,</span> <span class="token char">'content'</span><span class="token operator">:</span> response<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> response<span class="token punctuation">,</span> messages

        <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Langchain调用</span></span>

    def <span class="token function">_call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> prompt<span class="token operator">:</span> str<span class="token punctuation">,</span> stop<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"&lt;|user|>"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> run_manager<span class="token operator">=</span>None<span class="token punctuation">,</span> <span class="token operator">*</span><span class="token operator">*</span>kwargs<span class="token punctuation">)</span><span class="token operator">:</span>
        # 主要调用chat_stream实现
        response<span class="token punctuation">,</span> self<span class="token punctuation">.</span>history <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">chat_stream</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">,</span> self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">,</span> prompt<span class="token punctuation">,</span> self<span class="token punctuation">.</span>history<span class="token punctuation">)</span>

        <span class="token keyword">return</span> response

    def <span class="token function">query_only</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query<span class="token punctuation">)</span><span class="token operator">:</span>
        # 当使用RAG技术时会出现用户输入存在大量的参考资料，导致模型难以理解整体上下文内容。
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token char">'role'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token char">'user'</span><span class="token operator">:</span>
            self<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token char">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> query

    def <span class="token function">get_history</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-></span> List<span class="token operator">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>history

    def <span class="token function">delete_history</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token operator">:</span>
        del self<span class="token punctuation">.</span>history
        self<span class="token punctuation">.</span>history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>其中增加了一些采样参数：</p>
<ul>
<li>temperature：控制生成文本的随机性。温度高时，生成的文本更加多样、创意，但也可能不太连贯；温度低时，文本更稳定，但可能缺乏创意。</li>
<li>top_p：控制生成词汇的范围。模型会选择一些最有可能的词，直到这些词的概率总和达到<code>top_p</code>指定的阈值。<code>top_p</code>值越小，生成的内容越保守，越大则生成的内容更有变化。</li>
</ul>
<p>使用时应当先设定参数：do_sample=True，代表启用，否则不使用参数。</p>
<p>上面的例子并没有使用参数。</p>
<p>使用例：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    MODEL <span class="token operator">=</span> <span class="token string">"Qwen2.5-Math-7B"</span>
    llm <span class="token operator">=</span> QwenMath<span class="token punctuation">(</span><span class="token punctuation">)</span>
    llm<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span>MODEL<span class="token punctuation">)</span>

    query_ <span class="token operator">=</span> <span class="token string">"3加上5等于几"</span>
    res <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>query_<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
        </article>
        <section class="post-near">
            <ul>
                
                    <li>上一篇: <a href="/2025/03/03/RAG%E7%9A%84%E8%AE%A4%E8%AF%86%E4%B8%8E%E6%9E%84%E5%BB%BA/">RAG的认识与构建</a></li>
                
                
                    <li>下一篇: <a href="/2025/02/17/database-huadb4/">数据库内核实验报告四：查询执行</a></li>
                
            </ul>
        </section>
        
            <section class="post-tags">
            <a class="-none-link" href="/tags/Qwen/" rel="tag">Qwen</a>
            </section>
        
    
        <section class="post-author">
        
            <figure class="author-avatar">
                <img src="https://avatars.githubusercontent.com/u/62082723" alt="Mai Icy" />
            </figure>
        
            <div class="author-info">
                <h4>Mai Icy</h4>
                <p>wwwwwww</p>
            </div>
        </section>
    
    </div>
</main>

    <footer>
    <div class="buttons">
        <a class="to-top" href="#"></a>
    </div>
    <div class="wrap min">
        <section class="widget">
            <div class="row">
                <div class="col-m-4">
                    <h3 class="title-recent">最新文章：</h3>
                    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/04/29/%E5%9C%A8%20surfacebook2%20%E4%B8%8A%E5%AE%89%E8%A3%85%20ubuntu%20%E5%8F%8C%E7%B3%BB%E7%BB%9F/">在 surfacebook2 上安装 ubuntu 双系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/04/21/%E4%BD%BF%E7%94%A8%20Bind%20%E6%90%AD%E5%BB%BA%20DNS%20%E6%9C%8D%E5%8A%A1%E5%99%A8/">使用 Bind 搭建 DNS 服务器</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/04/14/MCP%E5%8D%8F%E8%AE%AE%E4%BB%8B%E7%BB%8D/">MCP协议介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/04/07/Linux%20%E4%B8%8A%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6/">Linux 上的压缩文件</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/04/05/Docker%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E5%AD%A6%E4%B9%A0/">Docker基本使用学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/03/29/Ubuntu%20%E4%BD%BF%E7%94%A8%20Nginx%20%E6%90%AD%E5%BB%BA%20WebDAV/">Ubuntu 使用 Nginx 搭建 WebDAV</a></li></ul>
                </div>
                <div class="col-m-4">
                    <h3 class="title-date">时光机：</h3>
                    <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/04/">April 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">March 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">February 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/01/">January 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">December 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/11/">November 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/09/">September 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">August 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/07/">July 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li></ul>
                </div>
                <div class="col-m-4">
                    <h3 class="title-tags">标签云：</h3>
                    <a href="/tags/2-SAT/" style="font-size: 10px;">2-SAT</a> <a href="/tags/3D-3D-ICP/" style="font-size: 10px;">3D-3D:ICP</a> <a href="/tags/AC%E8%87%AA%E5%8A%A8%E6%9C%BA/" style="font-size: 10px;">AC自动机</a> <a href="/tags/ARISE%E4%BC%98%E5%8C%96/" style="font-size: 10px;">ARISE优化</a> <a href="/tags/B-%E6%A0%91/" style="font-size: 10px;">B+树</a> <a href="/tags/BitTorrent/" style="font-size: 10px;">BitTorrent</a> <a href="/tags/C/" style="font-size: 11.43px;">C</a> <a href="/tags/CDN/" style="font-size: 10px;">CDN</a> <a href="/tags/CDQ%E5%88%86%E6%B2%BB/" style="font-size: 10px;">CDQ分治</a> <a href="/tags/DNS/" style="font-size: 11.43px;">DNS</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/HTTP%E6%B5%81/" style="font-size: 10px;">HTTP流</a> <a href="/tags/KMP/" style="font-size: 10px;">KMP</a> <a href="/tags/KNN/" style="font-size: 10px;">KNN</a> <a href="/tags/LDA/" style="font-size: 10px;">LDA</a> <a href="/tags/LLE/" style="font-size: 10px;">LLE</a> <a href="/tags/LSA/" style="font-size: 10px;">LSA</a> <a href="/tags/LSM%E6%A0%91/" style="font-size: 10px;">LSM树</a> <a href="/tags/LightHouse/" style="font-size: 10px;">LightHouse</a> <a href="/tags/Linux/" style="font-size: 11.43px;">Linux</a> <a href="/tags/MCP/" style="font-size: 10px;">MCP</a> <a href="/tags/Manacher%E7%AE%97%E6%B3%95/" style="font-size: 10px;">Manacher算法</a> <a href="/tags/NMF/" style="font-size: 10px;">NMF</a> <a href="/tags/Nginx/" style="font-size: 10px;">Nginx</a> <a href="/tags/P2P/" style="font-size: 10px;">P2P</a> <a href="/tags/PCA/" style="font-size: 10px;">PCA</a> <a href="/tags/Qwen/" style="font-size: 10px;">Qwen</a> <a href="/tags/RAG/" style="font-size: 10px;">RAG</a> <a href="/tags/RDT/" style="font-size: 10px;">RDT</a> <a href="/tags/SLAM/" style="font-size: 10px;">SLAM</a> <a href="/tags/SMTP-POP3-IMAP/" style="font-size: 10px;">SMTP/POP3/IMAP</a> <a href="/tags/ST%E8%A1%A8/" style="font-size: 10px;">ST表</a> <a href="/tags/TCP/" style="font-size: 10px;">TCP</a> <a href="/tags/UDP/" style="font-size: 10px;">UDP</a> <a href="/tags/WebDAV/" style="font-size: 10px;">WebDAV</a> <a href="/tags/diesel/" style="font-size: 10px;">diesel</a> <a href="/tags/epoll/" style="font-size: 10px;">epoll</a> <a href="/tags/http/" style="font-size: 10px;">http</a> <a href="/tags/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/" style="font-size: 10px;">io多路复用</a> <a href="/tags/k-means/" style="font-size: 10px;">k-means</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/python/" style="font-size: 14.29px;">python</a> <a href="/tags/redo-undo%E6%97%A5%E5%BF%97/" style="font-size: 10px;">redo/undo日志</a> <a href="/tags/requests/" style="font-size: 11.43px;">requests</a> <a href="/tags/t-SNE/" style="font-size: 10px;">t-SNE</a> <a href="/tags/tarjan/" style="font-size: 10px;">tarjan</a> <a href="/tags/web%E7%BC%93%E5%AD%98/" style="font-size: 10px;">web缓存</a> <a href="/tags/%E4%B8%AD%E5%9B%BD%E5%89%A9%E4%BD%99%E5%AE%9A%E7%90%86/" style="font-size: 10px;">中国剩余定理</a> <a href="/tags/%E4%B9%90%E8%A7%82%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/" style="font-size: 10px;">乐观并发控制</a> <a href="/tags/%E4%BA%8B%E5%8A%A1/" style="font-size: 10px;">事务</a> <a href="/tags/%E4%BA%8C%E5%88%86%E5%9B%BE%E5%8C%B9%E9%85%8D/" style="font-size: 10px;">二分图匹配</a> <a href="/tags/%E4%BA%8C%E5%88%86%E7%AD%94%E6%A1%88/" style="font-size: 10px;">二分答案</a> <a href="/tags/%E4%BD%8D%E5%9B%BE%E7%B4%A2%E5%BC%95/" style="font-size: 10px;">位图索引</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 11.43px;">动态规划</a> <a href="/tags/%E5%8D%8F%E8%AE%AE%E5%88%86%E5%B1%82/" style="font-size: 10px;">协议分层</a> <a href="/tags/%E5%8F%8C%E8%BF%9E%E9%80%9A%E5%88%86%E9%87%8F/" style="font-size: 10px;">双连通分量</a> <a href="/tags/%E5%90%8C%E4%BD%99/" style="font-size: 10px;">同余</a> <a href="/tags/%E5%90%8C%E4%BD%99%E9%80%86%E5%85%83/" style="font-size: 10px;">同余逆元</a> <a href="/tags/%E5%90%8E%E7%BC%80SA/" style="font-size: 10px;">后缀SA</a> <a href="/tags/%E5%93%88%E5%B8%8C%E7%B4%A2%E5%BC%95/" style="font-size: 10px;">哈希索引</a> <a href="/tags/%E5%9B%BE%E7%AE%97%E6%B3%95/" style="font-size: 14.29px;">图算法</a> <a href="/tags/%E5%9B%BE%E8%AE%BA/" style="font-size: 14.29px;">图论</a> <a href="/tags/%E5%9F%BA%E7%8E%AF%E6%A0%91/" style="font-size: 10px;">基环树</a> <a href="/tags/%E5%A4%9A%E7%89%88%E6%9C%AC%E6%9C%BA%E5%88%B6/" style="font-size: 10px;">多版本机制</a> <a href="/tags/%E5%A4%9A%E7%BB%B4%E7%B4%A2%E5%BC%95/" style="font-size: 10px;">多维索引</a> <a href="/tags/%E5%A4%9A%E8%B7%AF%E5%88%86%E8%A7%A3/" style="font-size: 10px;">多路分解</a> <a href="/tags/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/" style="font-size: 10px;">多路复用</a> <a href="/tags/%E5%AD%97%E5%85%B8%E6%A0%91/" style="font-size: 10px;">字典树</a> <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" style="font-size: 10px;">字符串</a> <a href="/tags/%E5%AE%B9%E6%96%A5%E5%8E%9F%E7%90%86/" style="font-size: 10px;">容斥原理</a> <a href="/tags/%E5%B7%AE%E5%88%86%E7%BA%A6%E6%9D%9F/" style="font-size: 10px;">差分约束</a> <a href="/tags/%E5%BA%B7%E6%89%98%E5%B1%95%E5%BC%80/" style="font-size: 10px;">康托展开</a> <a href="/tags/%E5%BC%82%E6%88%96%E5%93%88%E5%B8%8C/" style="font-size: 10px;">异或哈希</a> <a href="/tags/%E5%BC%82%E6%AD%A5/" style="font-size: 10px;">异步</a> <a href="/tags/%E5%BC%BA%E8%81%94%E9%80%9A%E5%88%86%E9%87%8F/" style="font-size: 11.43px;">强联通分量</a> <a href="/tags/%E5%BF%AB%E9%80%9F%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2FFT/" style="font-size: 10px;">快速傅里叶变换FFT</a> <a href="/tags/%E5%BF%AB%E9%80%9F%E5%B9%82/" style="font-size: 10px;">快速幂</a> <a href="/tags/%E6%82%B2%E8%A7%82%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/" style="font-size: 10px;">悲观并发控制</a> <a href="/tags/%E6%8E%A5%E5%85%A5%E6%8A%80%E6%9C%AF/" style="font-size: 10px;">接入技术</a> <a href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" style="font-size: 10px;">支持向量机</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 17.14px;">数据库</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%98%E5%82%A8/" style="font-size: 10px;">数据库存储</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C/" style="font-size: 15.71px;">数据库实验</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 10px;">数据结构</a> <a href="/tags/%E6%95%B0%E8%AE%BA/" style="font-size: 10px;">数论</a> <a href="/tags/%E6%97%B6%E9%97%B4%E6%88%B3%E6%8E%92%E5%BA%8F%E6%9C%BA%E5%88%B6/" style="font-size: 10px;">时间戳排序机制</a> <a href="/tags/%E6%9C%80%E5%A4%A7%E6%B5%81/" style="font-size: 10px;">最大流</a> <a href="/tags/%E6%9C%80%E5%B0%8F%E5%89%B2/" style="font-size: 10px;">最小割</a> <a href="/tags/%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84/" style="font-size: 10px;">最短路径</a> <a href="/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/" style="font-size: 10px;">朴素贝叶斯</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 17.14px;">机器学习</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A6%81/" style="font-size: 10px;">机器学习概要</a> <a href="/tags/%E6%9E%81%E8%A7%92%E6%8E%92%E5%BA%8F/" style="font-size: 10px;">极角排序</a> <a href="/tags/%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/" style="font-size: 10px;">查询优化</a> <a href="/tags/%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86/" style="font-size: 10px;">查询处理</a> <a href="/tags/%E6%9F%A5%E8%AF%A2%E6%89%A7%E8%A1%8C/" style="font-size: 10px;">查询执行</a> <a href="/tags/%E6%A0%91%E4%B8%8A%E5%90%AF%E5%8F%91%E5%BC%8F%E5%90%88%E5%B9%B6/" style="font-size: 10px;">树上启发式合并</a> <a href="/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/" style="font-size: 10px;">树状数组</a> <a href="/tags/%E6%A0%91%E9%93%BE%E5%89%96%E5%88%86/" style="font-size: 10px;">树链剖分</a> <a href="/tags/%E6%A0%B9%E5%8F%B7%E5%88%86%E6%B2%BB/" style="font-size: 10px;">根号分治</a> <a href="/tags/%E6%AD%A3%E5%88%99%E5%8C%96/" style="font-size: 10px;">正则化</a> <a href="/tags/%E6%AF%8D%E5%87%BD%E6%95%B0/" style="font-size: 10px;">母函数</a> <a href="/tags/%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/" style="font-size: 10px;">混合高斯分布</a> <a href="/tags/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/" style="font-size: 11.43px;">源码阅读</a> <a href="/tags/%E7%8A%B6%E6%80%81%E5%8E%8B%E7%BC%A9/" style="font-size: 10px;">状态压缩</a> <a href="/tags/%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6/" style="font-size: 10px;">电子邮件</a> <a href="/tags/%E7%9F%A9%E9%98%B5/" style="font-size: 10px;">矩阵</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">神经网络</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 20px;">算法</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">线性回归</a> <a href="/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91/" style="font-size: 10px;">线段树</a> <a href="/tags/%E7%BB%84%E5%90%88%E5%8D%9A%E5%BC%88/" style="font-size: 10px;">组合博弈</a> <a href="/tags/%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">网络</a> <a href="/tags/%E7%BD%91%E7%BB%9C%E6%B5%81/" style="font-size: 12.86px;">网络流</a> <a href="/tags/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/" style="font-size: 10px;">网络爬虫</a> <a href="/tags/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/" style="font-size: 10px;">背包问题</a> <a href="/tags/%E8%8E%AB%E6%AF%94%E4%B9%8C%E6%96%AF%E5%8F%8D%E6%BC%94/" style="font-size: 10px;">莫比乌斯反演</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/" style="font-size: 10px;">计算几何</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 18.57px;">计算机网络</a> <a href="/tags/%E8%B4%AA%E5%BF%83/" style="font-size: 10px;">贪心</a> <a href="/tags/%E8%B4%B9%E7%94%A8%E6%B5%81/" style="font-size: 10px;">费用流</a> <a href="/tags/%E9%80%92%E6%8E%A8/" style="font-size: 10px;">递推</a> <a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">逻辑回归</a> <a href="/tags/%E9%94%81%E6%9C%BA%E5%88%B6/" style="font-size: 10px;">锁机制</a> <a href="/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/" style="font-size: 10px;">随机森林</a>
                </div>
            </div>
        </section>
        <section class="sub-footer">
            <p>© 2025 <a href="/">Mai Icy</a>. All Rights Reserved. Theme By <a href="https://github.com/Dreamer-Paul/Hingle" target="_blank" rel="nofollow">Hingle</a>.</p>
        </section>
    </div>
</footer>


<script src="/static/kico.js"></script>
<script src="/static/hingle.js"></script>


<script>var hingle = new Paul_Hingle({"copyright":true,"night":true});</script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
